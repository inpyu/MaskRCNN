{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBIRhqtYBk1-"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import random\n",
        "import os\n",
        "import natsort\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse # parser\n",
        "from os.path import basename #path\n",
        "import numpy as np #numpy\n",
        "import torch #torch\n",
        "import cv2 # cv\n",
        "import torchvision #torch vision\n",
        "import colorsys\n",
        "import random\n",
        "from random import randint\n",
        "import glob\n",
        "import time\n",
        "import natsort # sort file list by number\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "from scipy import ndimage\n",
        "import shutil"
      ],
      "metadata": {
        "id": "5_GjReiHDfRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader"
      ],
      "metadata": {
        "id": "mhQdVKS0ZNOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_ = None):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.files_A = sorted(glob.glob(os.path.join(root ) + '*.*'))        \n",
        "        self.files_A = natsort.natsorted(self.files_A)        \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        item_A = self.transform(Image.open(self.files_A[index]))        \n",
        "        return {'A': item_A}\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.files_A)"
      ],
      "metadata": {
        "id": "ieqKIRenB7z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"torch vision version:\" +   torchvision.__version__)\n",
        "print(\"torch version:\" + torch.__version__)\n",
        "print(\"torch cuda version:\" + torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwpcwqSsDmcZ",
        "outputId": "2e958e4f-db1f-454e-e372-8327ea7a1b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch vision version:0.14.0+cu116\n",
            "torch version:1.13.0+cu116\n",
            "torch cuda version:11.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--batchSize', type=int, default=1, help='size of the batches')\n",
        "parser.add_argument('--root', type = str, default = './', help = 'root dir')\n",
        "parser.add_argument('--data_path', type = str, default = './images/' , help = 'dataset dir')\n",
        "parser.add_argument('--save_path', type = str, default = './output/' , help = 'result path')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSUcpnNlDyXy",
        "outputId": "f9bda01e-5114-40f5-bdb0-a3bfaf7efd61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--save_path'], dest='save_path', nargs=None, const=None, default='./output/', type=<class 'str'>, choices=None, help='result path', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument('--cuda', action = 'store_false', help = 'use GPU computation')\n",
        "parser.add_argument('--n_cpu', type=int, default=8, help='number of cpu threads to use during batch generation')\n",
        "parser.add_argument('--input_nc', type=int, default=3, help='number of channels of input data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwfRj6TDILVq",
        "outputId": "1f21c28f-3365-48b1-f1de-ad1d166febac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreAction(option_strings=['--input_nc'], dest='input_nc', nargs=None, const=None, default=3, type=<class 'int'>, choices=None, help='number of channels of input data', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.add_argument('-f')\n",
        "opt = parser.parse_args()"
      ],
      "metadata": {
        "id": "Wuez2AuDDywm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 모델 구조 파악"
      ],
      "metadata": {
        "id": "0JK02COvZMM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COCO Class names\n",
        "# Index of the class in the list is its ID. For example, to get ID of\n",
        "# the teddy bear class, use: class_names.index('teddy bear')\n",
        "# 모델에서 분류할 수 있는 class의 name을 list로 만듦.\n",
        "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
        "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
        "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
        "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
        "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
        "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
        "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
        "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
        "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
        "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
        "               'teddy bear', 'hair drier', 'toothbrush']\n"
      ],
      "metadata": {
        "id": "a-xhVhTDEavN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#######################################\n",
        "# Networks Definition\n",
        "# TorchVision에 존재하는 maskrcnn을 사용하고자 함.\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
        "#if torch.cuda.is_available():\n",
        "#  print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "#  model.cuda()\n",
        "#######################################\n",
        "\n",
        "\n",
        "#####################################################\n",
        "# Set model's test mode\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "3gRH8JB2Btxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init(data_path):\n",
        "    #Dataset Loader\n",
        "    transforms_ = [ transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
        "    dataloader = DataLoader(ImageDataset(data_path, transforms_=transforms_), \n",
        "                            batch_size=opt.batchSize, shuffle=False, num_workers=opt.n_cpu)\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "uv3KqJIdCBgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def human_remove(image,mask,labels,file_name,save_path):\n",
        "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)    \n",
        "    image = cv2.cvtColor(image,cv2.COLOR_RGB2RGBA)\n",
        "    \n",
        "    image[:,:,3] = 255.0\n",
        "    channel = image.shape[2]\n",
        "    area = 0    \n",
        "    _,_,w,h = mask.shape\n",
        "    for n in range(mask.shape[0]):\n",
        "            if labels[n] == 1:   #1이 human임 !!             \n",
        "                mask[n] = np.where(mask[n] >0.5, 255,0)\n",
        "            else :\n",
        "                continue        \n",
        "    for n in range(mask.shape[0]):\n",
        "            if labels[n] == 1:\n",
        "                for c in range(channel):                \n",
        "                    image[:,:,c] = np.where(mask[n] == 255, 0, image[:,:,c])\n",
        "            else :\n",
        "                continue                \n",
        "    #image save\n",
        "    cv2.imwrite(save_path +'seg_' + file_name ,image)"
      ],
      "metadata": {
        "id": "og0P6h0pBykd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mask를 적용해 출력하고자 할때 사용\n",
        "def apply_mask(image,mask,labels,boxes,file_name,save_path):\n",
        "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)    \n",
        "    # image = cv2.cvtColor(image,cv2.COLOR_RGB2RGBA)\n",
        "    \n",
        "    alpha = 1 \n",
        "    beta = 0.6 # transparency for the segmentation map\n",
        "    gamma = 0 # scalar added to each sum\n",
        "    COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))    \n",
        "    channel = image.shape[2]\n",
        "    area = 0    \n",
        "    _,_,w,h = mask.shape    \n",
        "    segmentation_map = np.zeros((w,h,3),np.uint8)\n",
        "    \n",
        "    for n in range(mask.shape[0]): \n",
        "        if labels[n] == 0:\n",
        "            continue\n",
        "        else:\n",
        "            color = COLORS[random.randrange(0,len(COLORS))]\n",
        "            segmentation_map[:,:,0] = np.where(mask[n] > 0.5, COLORS[labels[n]][0], 0)\n",
        "            segmentation_map[:,:,1] = np.where(mask[n] > 0.5, COLORS[labels[n]][1], 0)\n",
        "            segmentation_map[:,:,2] = np.where(mask[n] > 0.5, COLORS[labels[n]][2], 0)            \n",
        "            image = cv2.addWeighted(image,alpha,segmentation_map,beta,gamma,dtype = cv2.CV_8U)\n",
        "        # draw the bounding boxes around the objects        \n",
        "        cv2.rectangle(image, boxes[n][0], boxes[n][1],color = color ,thickness = 2)\n",
        "        \n",
        "        print(class_names[labels[n]])\n",
        "        # put the label text above the objects\n",
        "        cv2.putText(image , class_names[labels[n]], (boxes[n][0][0], boxes[n][0][1]-10), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, color, \n",
        "                    thickness=2, lineType=cv2.LINE_AA)\n",
        "    #image save\n",
        "    cv2.imwrite(save_path +'seg_2' + file_name ,image) "
      ],
      "metadata": {
        "id": "fdu5uuMxEoqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mask의 색을 random하게 배정하기 위한 함수 \n",
        "def random_colors(N, bright=True):\n",
        "    \"\"\"\n",
        "    Generate random colors.\n",
        "    To get visually distinct colors, generate them in HSV space then\n",
        "    convert to RGB.\n",
        "    \"\"\"\n",
        "    brightness = 1.0 if bright else 0.7\n",
        "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
        "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
        "    random.shuffle(colors)\n",
        "    return colors"
      ],
      "metadata": {
        "id": "MNzSmf2wEphK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#텐서를 맞는 형태로 변형\n",
        "def tensor2im(tensor):\n",
        "    # if opt.cuda == True:\n",
        "        # tensor = 127.5*(tensor[0].data.cpu().float().numpy() +1.0)\n",
        "    # else:\n",
        "    tensor = 127.5 *(tensor[0].data.float().numpy() +1.0)\n",
        "    img = tensor.astype(np.uint8) #tensor의 type을 unit8로 변경\n",
        "    img = np.transpose(tensor,(1,2,0))    \n",
        "    return img"
      ],
      "metadata": {
        "id": "KnmZx0YFErGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_rcnn(file_list,dataloader,save_path):\n",
        "    for i,batch in enumerate(dataloader):        \n",
        "    \n",
        "        img = batch['A']      \n",
        "        print(file_list[i])\n",
        "        \n",
        "        #use cuda\n",
        "        #result = model(img.to('cuda'))\n",
        "        #use cpu\n",
        "        result = model(img) #이미지를 maskRCNN에 넣은 결과를 result에 넣게 됨.\n",
        "        \n",
        "        image = tensor2im(img) #apply_mask, human_remove 등을 하기 위한 tensor 생성\n",
        "\n",
        "        scores = list(result[0]['scores'].detach().numpy())\n",
        "        thresholded_preds_inidices = [scores.index(i) for i in scores if i > 0.965] # score값이 0.965 이상에 해당하는 것들만 넣고자 함.\n",
        "        thresholded_preds_count = len(thresholded_preds_inidices)   #0.965 이상인 것들의 수를 따로 저장     \n",
        "        mask = result[0]['masks']\n",
        "        mask = mask[:thresholded_preds_count] # 각각의 것에 대한 mask 진행\n",
        "        labels = result[0]['labels']        # label을 붙임\n",
        "        boxes = [[(int(i[0]), int(i[1])), (int(i[2]), int(i[3]))]  for i in result[0]['boxes']]\n",
        "        boxes = boxes[:thresholded_preds_count]\n",
        "        \n",
        "        mask = mask.data.float().numpy()        \n",
        "        #사람을 지우고 싶을때\n",
        "        # human_remove(image,mask,labels,file_list[i],save_path)\n",
        "        # 모든 객체에 segmetation과 박스를 출력하고 싶을때\n",
        "        apply_mask(image,mask,labels,boxes,file_list[i],save_path)"
      ],
      "metadata": {
        "id": "bgWJJUvcBwEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_mask(image,mask,labels,boxes,file_name,save_path):\n",
        "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)    \n",
        "    # image = cv2.cvtColor(image,cv2.COLOR_RGB2RGBA)\n",
        "    \n",
        "    alpha = 1 \n",
        "    beta = 0.6 # transparency for the segmentation map -> 투명도 조절\n",
        "    gamma = 0 # scalar added to each sum\n",
        "    COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))    # 랜덤색상 선정\n",
        "    channel = image.shape[2]\n",
        "    area = 0    \n",
        "    _,_,w,h = mask.shape    \n",
        "    segmentation_map = np.zeros((w,h,3),np.uint8)\n",
        "    \n",
        "    for n in range(mask.shape[0]): \n",
        "        if labels[n] == 0:\n",
        "            continue\n",
        "        else:\n",
        "            color = COLORS[random.randrange(0,len(COLORS))]\n",
        "            segmentation_map[:,:,0] = np.where(mask[n] > 0.5, COLORS[labels[n]][0], 0)\n",
        "            segmentation_map[:,:,1] = np.where(mask[n] > 0.5, COLORS[labels[n]][1], 0)\n",
        "            segmentation_map[:,:,2] = np.where(mask[n] > 0.5, COLORS[labels[n]][2], 0)            \n",
        "            image = cv2.addWeighted(image,alpha,segmentation_map,beta,gamma,dtype = cv2.CV_8U)\n",
        "        # draw the bounding boxes around the objects        \n",
        "        cv2.rectangle(image, boxes[n][0], boxes[n][1],color = color ,thickness = 2)\n",
        "        \n",
        "        print(class_names[labels[n]])\n",
        "        # put the label text above the objects\n",
        "        cv2.putText(image , class_names[labels[n]], (boxes[n][0][0], boxes[n][0][1]-10), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, color, \n",
        "                    thickness=2, lineType=cv2.LINE_AA)\n",
        "    #image save\n",
        "    cv2.imwrite(save_path +'seg_2' + file_name ,image)"
      ],
      "metadata": {
        "id": "HKM_bHRtB0fK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    if not os.path.exists(opt.save_path):\n",
        "            os.makedirs(opt.save_path)\n",
        "    if not os.path.exists(opt.data_path):\n",
        "        os.makedirs(opt.data_path)\n",
        "    file_list = os.listdir(opt.data_path)\n",
        "    file_list = natsort.natsorted(file_list)    \n",
        "    dataloader = init(opt.data_path)\n",
        "    mask_rcnn(file_list,dataloader,opt.save_path) "
      ],
      "metadata": {
        "id": "h2HMXUV9EwRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":    \n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmnemSl5Eyl1",
        "outputId": "d1a5f7e7-4f9f-450e-e6b8-6cadd148790a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1111.jpg\n",
            "person\n",
            "car\n",
            "person\n",
            "person\n"
          ]
        }
      ]
    }
  ]
}